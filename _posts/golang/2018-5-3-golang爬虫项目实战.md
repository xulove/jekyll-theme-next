---
title: golang爬虫项目实战(一)
description: 实现一个简单的爬虫项目框架。
categories:
 - golang爬虫项目实战
 - golang
 - 爬虫
tags:
 - golang
 - 爬虫
---



## 1、爬取的页面

我们爬虫的主页面是`http://www.zhenai.com/zhenghun` ，珍爱网的城市列表界面

## 2、爬虫项目结构

> project
>
> ——engine
>
> ​	——engine.go
>
> ​	——request.go
>
> fetcher
>
> ​	——fetcher.go
>
> zhenai
>
> ​	——parse
>
> ​		——cityListParse.go
>
> main.go

## 3、爬虫代码及解释

> 这是这个爬虫的引擎，它相当于人的大脑，调用解析器，下载器等协同配合工作。
>
> 项目入口main启动引擎engine时给它传入了request结构体对象，结构体对象包含两个字段，一个目标页面Url，一个页面解析器parser。
>
> 引擎首先调用下载器fetcher的`FetchData()`方法，下面目标url页面的数据，返回二进制字节数组。
>
> 然后调用传进来的解析器`r.ParseFunc()` （解析器就是说简单点，就是我们找到页面中我们想要的内容，然后再把这些内容按照要求封装成需要的对象），此处解析出城市列表，封装成request对象，然后添加到请求的request对象数组中。当没有request对象是`len(r)>0` 不满足时，爬虫结束

**engine.go**

```go
package engine

import (
	"xu.com/learngo/0503-complete/fetcher"
	"log"
	"fmt"
)
func Run(r ...Request){
	for len(r)>0 {
		firstRequest:=r[0]
		r=r[1:]
		fmt.Println("即将请求：",firstRequest.Url)
		all,err:=fetcher.FetchData(firstRequest.Url)
		if err != nil {
			log.Printf("%v\n",err)
		}
		result:=firstRequest.ParseFunc(all)
		r=append(r, result.R...)
	}
}

```

**request.go**

> 请求对象Request
>
> RequestResult：代表我们的解析后返回的结构，其中`RequestResult.R`就是我们的请求对象数组 

```go
package engine
type Request struct {
	Url string
	ParseFunc func(b []byte) RequestResult
}
type RequestResult struct {
	Item []interface{}
	R []Request
}
// 空的解析器
func NilParser(b []byte) (r RequestResult) {
	return r
}
```

**fetcher.go**

> 下载器，根据传入的URl下载对应页面的数据，返回字节数组。

```go
package fetcher

import (
	"net/http"
	"io/ioutil"
	"io"
	"golang.org/x/text/encoding"
	"bufio"
	"golang.org/x/text/encoding/unicode"
	"golang.org/x/net/html/charset"
	"golang.org/x/text/transform"
	"fmt"
)
func FetchData(url string)([]byte,error){
	res,err:=http.Get(url)
	defer res.Body.Close()
	if err != nil {
		return nil,err
	}
	if res.StatusCode != http.StatusOK {
		return nil,fmt.Errorf("Error status code: %d",res.StatusCode)
	}
	//判断编码格式
	code:=determinEncoding(res.Body)
	utf8ResReader:=transform.NewReader(res.Body,code.NewEncoder())
	return ioutil.ReadAll(utf8ResReader)
}
// 将response.Body 作为参数传入到函数中
// 会自动返回编码格式
func determinEncoding(r io.Reader)encoding.Encoding{
	bytes, err := bufio.NewReader(r).Peek(1024)
	if err != nil {
		//panic(err)
		return unicode.UTF8
	}
	// 查找编码格式
	e, _, _ := charset.DetermineEncoding(bytes, "")
	// 返回编码格式
	return e
}
/*
解释说明：
res.body 是一个io.readCloser对象
type ReadCloser interface {
	Reader
	Closer
}

ReadClose是一个接口,包括了Reader和Closer的所有方法。难道接口还可以有继承操作吗？
在上面的例子中实现了ReadCloser的结构体，不光要实现ReadCloser的方法，还需要实现Reader和Closer中的方法

 */
```

**cityListParse.go**

> 城市列表解析器，每个页面都应该有自己单独的解析器。解析页面字节数组，找到自己需要的内容，返回封装好的request对象。

```go
package parse

import (
	"xu.com/learngo/0503-complete/engine"
	"regexp"
)
const regexpString = `<a href="(http://www.zhenai.com/zhenghun/[a-z0-9]+)"[^>].+>([^<].+)</a>`package main

import (
	"xu.com/learngo/0503-complete/engine"
	"xu.com/learngo/0503-complete/zhenai/parse"
)
const CityListUrl  = "http://www.zhenai.com/zhenghun"
func main() {
	engine.Run(engine.Request{CityListUrl,parse.CityListParser})
}

func CityListParser(b []byte)(r engine.RequestResult){
	match:=regexp.MustCompile(regexpString)

	bytes:=match.FindAllSubmatch(b,-1)
	//fmt.Println(bytes)
	for _, v :=range bytes {
		r.Item=append(r.Item, v[2])
		r.R=append(r.R,engine.Request{string(v[1]),engine.NilParser})
	}
	return
}
```

**main.go**

> 程序入口，调用引擎，启动程序

```go
package main

import (
	"xu.com/learngo/0503-complete/engine"
	"xu.com/learngo/0503-complete/zhenai/parse"
)
const CityListUrl  = "http://www.zhenai.com/zhenghun"
func main() {
	engine.Run(engine.Request{CityListUrl,parse.CityListParser})
}

```



​		